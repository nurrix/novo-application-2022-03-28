{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e525179e-e61d-4f1e-95a1-bc0e3219a377",
   "metadata": {},
   "source": [
    "# Statistical test of Treatment A & B\n",
    "\n",
    "This is the analysis of Treatment A & B for the novo case for presentation on 2022-03-28 @ 13.00\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "348ba9d6-fb3e-44fa-9e80-45f92f9f1eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: c:\\Users\\Nurrix\\AppData\\Local\\Temp\\tmp8leujgel\n",
      "Requirement already satisfied: setuptools in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (58.1.0)\n",
      "Requirement already satisfied: pip in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (22.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.21.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: statistics in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.3.5)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: scipy in c:\\users\\nurrix\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.8.0)\n",
      "prereq modules installed\n",
      "imported modules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This section will simply import the necessary modules to run the program. \n",
    "These are all standard Python modules, so nothing strange should happen here.\n",
    "PLEASE have internet! \n",
    "'''\n",
    "\n",
    "# Install modules, if not already installed, we could make this quiet, but it doesnt really matter\n",
    "!{sys.executable} -m ensurepip\n",
    "!{sys.executable} -m pip install numpy pandas matplotlib statistics openpyxl scipy re\n",
    "\n",
    "print('prereq modules installed')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import re\n",
    "\n",
    "print('imported modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f339cfc-7f37-4b6a-a12d-d0bc574b0b48",
   "metadata": {},
   "source": [
    "# Clean up of data\n",
    "\n",
    "This section entails the cleanup of data. \n",
    "To avoid data curruption, The cleaned up data is saved into two new sheet in in the file 'cleaned-data.xlsx'.\n",
    "\n",
    "Initial data-inspection provided some thoughts.\n",
    "As we need to provide a descriptive table, we have some small issues with the data.\n",
    "\n",
    "\n",
    "For ADSL:\n",
    "- Three subjects are missing DIABDUR. i.e. ADSL Line 16 (Subject S001047) Is missing entry at DIABDUR and DIABDURU, So we can expect a few other subjects to be missing some numbers\n",
    "- S005025 is VERY tall. I believe it is a safe assumption that this subject was 181cm tall, and not 181 m tall, This should be corrected.\n",
    "- Weight is noted in both LB and KG, however, the table specifies KG, so we should convert all lb to kg. \n",
    "\n",
    "For ADLB:\n",
    "- Data is in Long format. Could be smart to correct it to wide, to ensure we are not missing any data for Visit 10, 14, 18, 22, 26, 30. \n",
    "    - This means that AVSIT should be segmented into Visitv2, and Week columns.\n",
    "- We are dividing the data into two PARAMCD's (of interest here at least) (at a glance these two correspond to FPG and HbA1c.. I will have to check to make sure)\n",
    "    - This might actually be smarter to seperate the data into two temporary dataframes here, so no confusion occurs here. And to ensure that no data is missing.\n",
    "- There has also been some issues with a few of the acquisitions of data. see ANL01FL != 'Y'\n",
    "    - see 'Retest Rule' and 'oroginal visit realloc'. Not sure what that means... \n",
    "        - In a real scenario I really should know this\n",
    "- Lets also make sure that the units for FPG remains mmol/L and HbA1c remains %\n",
    "- While we are checking, maybe some of the PARAM's are not only FPG or HbA1c.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86dfa8c1-4ebd-40bc-b6e7-42e856ad3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify variable constants\n",
    "\n",
    "MASTER_XLSX_NAME = 'src/data.xlsx'\n",
    "CLEAN_XLSX_NAME = 'src/clean-data.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32e7e0a4-4ec4-4ac1-b5e5-a1de81c49764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convertHeightCorrectly(value:float, unit:str) -> float:\n",
    "    \"\"\"\n",
    "    This function converts height from different unit (etc cm)\n",
    "    to m.\n",
    "    Also ensures that if height is < 100\n",
    "    \"\"\"\n",
    "    \n",
    "    unit_conv = float(value<100) + float(value>=100) * 0.01\n",
    "    if unit.lower() != 'm':\n",
    "        return np.nan\n",
    "\n",
    "    return value * unit_conv\n",
    "\n",
    "    \n",
    "def converWgt2Kg(value:float, unit:str) -> float:\n",
    "    \"\"\"\n",
    "    Converts weight into Kg\n",
    "    - if lb -> wgt * fLB2KG\n",
    "    else return wgt\n",
    "    \"\"\"\n",
    "    fLB2KG = 0.4535924 # conversion ratio from lb to kg\n",
    "    unit_conv = float(unit == 'lb') * fLB2KG + float(unit == 'kg')\n",
    "    return value * unit_conv\n",
    "\n",
    "def convertMonthsToYears(value:float, unit:str) -> float:\n",
    "    \"\"\"\n",
    "    Convert months into years\n",
    "    \"\"\"\n",
    "    \n",
    "    unit_conv = float(unit=='years' or unit=='years'.upper()) + float(unit=='months')*1.0/12.0\n",
    "    return value * unit_conv\n",
    "\n",
    "def my_filter(dfl, dfr):\n",
    "    \"\"\"\n",
    "    Filter system\n",
    "    \"\"\"\n",
    "    \n",
    "    return \n",
    "\n",
    "def extractWeekAndVisitsfromAVISIT(value:str):\n",
    "    \"\"\" This function returns a list of data with the week number\"\"\"\n",
    "    \n",
    "    nums = re.findall(r'\\d+', value)\n",
    "    return_value = {'Visit':int(nums[0]), 'Week':int(nums[1])} \n",
    "    return return_value\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e69d9eac-e085-4227-a58e-d479a72b9f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADSL\n",
      "ADLB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sheetname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADLB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     24\u001b[0m     ADLB \u001b[38;5;241m=\u001b[39m df_sheet\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 25\u001b[0m     ADLB[:,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVisit\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeek\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m ADLB\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: extractWeekAndVisitsfromAVISIT(value\u001b[38;5;241m=\u001b[39mrow\u001b[38;5;241m.\u001b[39mAVISIT), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ADLB)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Check \u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3835\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3823\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;124;03mAdd series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[38;5;124;03mensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3832\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   3834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m-> 3835\u001b[0m     \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[0;32m   3836\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m ):\n\u001b[0;32m   3839\u001b[0m     \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   3841\u001b[0m         existing_piece \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[key]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5008\u001b[0m, in \u001b[0;36mIndex.__contains__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   4974\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4975\u001b[0m \u001b[38;5;124;03m    Return a boolean indicating whether the provided key is in the index.\u001b[39;00m\n\u001b[0;32m   4976\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5006\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   5007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5008\u001b[0m     \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5009\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   5010\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# Open MASTER dataframe\n",
    "MASTER_DATAFRAME = pd.read_excel(MASTER_XLSX_NAME, sheet_name=None)\n",
    "\n",
    "clean_df = pd.DataFrame()\n",
    "\n",
    "for sheetname, df_sheet in MASTER_DATAFRAME.items():\n",
    "    # Iterate through every sheet in the master dataframe\n",
    "    print(sheetname)\n",
    "    if sheetname == 'ADSL':\n",
    "        # (sanity check), make sure that no subject is written twice here.\n",
    "        ADSL_num_dub_subj = len(df_sheet[df_sheet.SUBJID.duplicated()])\n",
    "        ADSL = df_sheet.copy()\n",
    "        # Create body weight DF\n",
    "        clean_df['AgeYears']              = df_sheet.apply(lambda row: convertMonthsToYears(  value=row.AGE    , unit=row.AGEU),     axis=1)\n",
    "        clean_df['HeightM']               = df_sheet.apply(lambda row: convertHeightCorrectly(value=row.HGTBL  , unit=row.HGTBLU),   axis=1)\n",
    "        clean_df['BodyWeightKg']          = df_sheet.apply(lambda row: converWgt2Kg(          value=row.WGTBL  , unit=row.WGTBLU),   axis=1)\n",
    "        clean_df['DiabetesDurationYears'] = df_sheet.apply(lambda row: convertMonthsToYears(  value=row.DIABDUR, unit=row.DIABDURU), axis=1)\n",
    "        #clean_df['AVISITS']               = df_sheet.apply(lambda row: extractWeekAndVisitsfromAVISIT(  value=row.AVISITS), axis=1)\n",
    "        #print(clean_ADSL_df)\n",
    "        #print(f'{sheetname} > Number of dublicate subj entries (should be 0) : {ADSL_num_dub_subj}')\n",
    "        continue\n",
    "    \n",
    "    if sheetname == 'ADLB':\n",
    "        ADLB = df_sheet.copy()\n",
    "        ADLB['Weeks', 'Visit'] = ADLB.apply(lambda row: extractWeekAndVisitsfromAVISIT(value=row.AVISIT), axis=1)\n",
    "        print(ADLB)\n",
    "        # Check \n",
    "        continue\n",
    "\n",
    "\n",
    "print(clean_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6861ff0-8383-4559-aedf-e7afa46f9604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SUBJID FASFL         TRTP             AVISIT  VISITNUM  \\\n",
      "2127  S101066     Y  Treatment B  Visit 10 (Week 0)        10   \n",
      "\n",
      "                PARAM  PARAMCD  AVAL AVALU ANL01FL     ANL01REA  \n",
      "2127  HbA1c Blood (%)  C64849B   7.9     %       N  Retest rule  \n"
     ]
    }
   ],
   "source": [
    "tmpdf = clean_df.copy()\n",
    "tmpdf['PARAMCD']='C64849B'\n",
    "tmpdf['VISITNUM']=10\n",
    "selectADLB = ADLB.loc[:, ['PARAMCD', 'VISITNUM', 'FASFL']]\n",
    "\n",
    "tf1 = ADLB[selectADLB.isin(['C64849B', 10, 'Y']).all(axis=1)]\n",
    "print(tf1[tf1.SUBJID.duplicated()])\n",
    "\n",
    "# selecttmpdf = tmpdf.loc[:, ['SUBJID', 'PARAMCD', 'VISITNUM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa44f1-2d98-417b-a070-ce47a4262c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd112b8-a702-438a-a5a5-a0231c302eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
